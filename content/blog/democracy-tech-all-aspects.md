+++
title = "Democracy in Tech - In All Aspects"
date = 2020-05-28
+++

I was originally going to write something along these lines next week, but there has has been news that has inspired me to change the purpose of this article.

Earlier this week, President Trump posted two Tweets, claiming that California's decision to move to entirely mail-in ballots will subject the results to be "substantially fraudulent".
When Twitter decided to add flags to those Tweets with links to articles fact-checking this, the conservative media was outraged, with Trump reportedly signing an executive order today that would make social media companies potentially legally liable for content made by their users.
This means that Twitter, Facebook, and other such companies will be legally liable somewhere along the spectrum of either their lack of fact-checking every political tweet to their decision to fact-check any political tweet.

But I'm not here to dispute the veracity of any tweet or news report.

In my last article, I talked about "ghost companies" -- companies that collect data on internet denizens without their knowledge.
Now, I'd like to talk about how to address concerns such as these by thinking about how democracy in tech would look like.
Here's what I think: I think that it is the responsibility of internet users to ensure that the internet is a good place to go.

Right now, Twitter and Facebook are in an interesting position.
After the Cambridge Analytica scandal, Mark Zuckerberg went to the nation's capital to talk to two panels in Congress: one from the Senate, and one from the House.
In particular, I find one quote from Mr. Zuckerberg profound: "We believe that in a democracy, it is important that people can see for themselves what politicians are saying."
This is my driving point: democracy is for the people.
It is not for the politicians, it is not for companies, it is for us - the people who (should) benefit most from having those things.
And yet, there has been pressure for these companies to either fact check more or to not fact check at all.
Why should these companies decide who's right and who's wrong?

I promise this ties into ghost companies too.
The companies we do know about are the ones that decide who gets to access our information.
Again, CNN has decided to allow Xandr to track us across the web, and what's to stop CNN from doing more?
I have not looked into more of the hundreds of communications that happen between my laptop and CNN and Xandr and potentially other companies' servers, but I don't need to to know that there is more than CNN only providing its news stories and basic subscription tracking, because I already know about Xandr's existence!

So, how do we fix these problems?
Well, there's a fairly straight-forward answer: democratize everything.
On Twitter, Facebook, Reddit, LinkedIn, whatever social media app you're using, there should be more democracy.
What does that look like?
Well, it looks almost exactly the same way it does now.
The crucial difference is that these tools should only provide you with a quick way to see user-submitted fact checks.
That's right, user-submitted.
To make this much less prone to trolls, spam, and other such things, there should be a voting system on these fact checks, and until the votes reach a certain threshold, the fact checks should be marked "unsure by the community."
(For those saying that bots could influence this system, I agree, but that's an issue with the FB/Twitter sign up process, which is not in scope.)
Then, the highest-voted fact checks are placed at the top of a list of all fact checks.
We already see this on Twitter with the "blue checkmark" next to user names, why don't we see this on posts?

For ghost companies, the process looks a little different, but the democratization remains true.
In the software development world, there's an idea that's been abbreviated as OSS (Open Source Software, where the code is available online), FOSS (Free/Open Source Software, which is OSS but also the software is free to use), and FLOSS (Free/Libre/Open Source Software, which is FOSS but derivations of the software can be used for the profit of the derivers).
Obviously, with these kinds of projects, there are so many issues that arise - companies do not want to share their intellectual property being the largest.
However, just as you can open the hood of a car to see all of the internal parts of the automobile, you should be able to inspect software to ensure that it's not doing something that you don't expect it to.
There are people that will "whistleblow" unsafe mechanical structures, but where are these protections for software?
Therefore, there should be a movement of companies releasing the source code for their software so that they could be held liable.
Obviously, for security reasons, certain things will have to be held privately (private keys, security-crucial government code, etc), but the vast majority of non-OSS isn't these; there should be a test to decide on whether your code shouldn't be open source.
This empowers the people to decide on how ethical a company is behaving, and whether or not that company is doing stuff behind the scenes that they shouldn't be doing.

Overall, this is just the tip of the iceberg.
There is so much more that we can do to enforce a healthy internet, free from spying, free from bad actors, and free from collusion.
And, most importantly, free from interference with our own personal freedoms.

[Originally posted to LinkedIn](https://www.linkedin.com/pulse/democracy-tech-all-aspects-colton-donnelly/)
